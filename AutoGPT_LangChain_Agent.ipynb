{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrochanav/CapstoneProject/blob/main/AutoGPT_LangChain_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f19c1f2a",
      "metadata": {
        "id": "f19c1f2a"
      },
      "source": [
        "# ü§ñ AutoGPT & AI Agents Using LangChain\n",
        "\n",
        "In this notebook, you will build an **AI agent** that can **fetch news, summarize content, and make recommendations** using **LangChain** and **LLMs**. You will also implement **memory persistence** for context-aware responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "798f3db9",
      "metadata": {
        "id": "798f3db9"
      },
      "source": [
        "## 1Ô∏è‚É£ Install Dependencies\n",
        "First, install the required libraries for LangChain, OpenAI API, and vector databases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c4d7a08",
      "metadata": {
        "id": "8c4d7a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acbfad0-2d28-45e7-9bce-936ae42db14f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.14.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai chromadb wikipedia serpapi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805cd31a",
      "metadata": {
        "id": "805cd31a"
      },
      "source": [
        "## 2Ô∏è‚É£ Set Up API Keys\n",
        "We will set up API keys for OpenAI and SerpAPI (for web search)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b73fce6a",
      "metadata": {
        "id": "b73fce6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed84fa3-188d-4deb-92a0-0b52a6f3634b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OPENAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set your API keys (replace with your own keys)\n",
        "import getpass\n",
        "\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Please enter your OPENAI API Key: \")\n",
        "serpapi_api_key = '7929aaa2dbb348e72c1c293fa631fbd9d4f026948b33595f0d91d249a19f34db'\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "os.environ['SERPAPI_API_KEY'] = serpapi_api_key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc20eb9",
      "metadata": {
        "id": "ccc20eb9"
      },
      "source": [
        "## 3Ô∏è‚É£ Load LLM and Define Helper Functions\n",
        "We will load a **pre-trained LLM** and create functions for querying the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install --upgrade langchain langchain-community\n"
      ],
      "metadata": {
        "id": "rAnp__VTkdlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7f767f-43f3-4195-bf2c-eda21ddfdd48"
      },
      "id": "rAnp__VTkdlN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6335ecb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6335ecb9",
        "outputId": "789be0cb-2e30-40c7-a6e1-5402d0413683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d07c49a23686>:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(model_name='text-davinci-003', temperature=0.5)\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Load LLM\n",
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.5)\n",
        "\n",
        "def generate_response(prompt):\n",
        "    response = llm(prompt)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3d56c7",
      "metadata": {
        "id": "6c3d56c7"
      },
      "source": [
        "## 4Ô∏è‚É£ Implement AI Assistant with Web Search & Summarization\n",
        "We create an **AI agent** that fetches **news, summarizes content**, and makes **recommendations**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall serpapi google-search-results -y\n",
        "!pip install --no-cache-dir google-search-results\n"
      ],
      "metadata": {
        "id": "LO7wNEOBlDnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10cb58f6-533f-4a5a-94f2-affe12daa289"
      },
      "id": "LO7wNEOBlDnx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping serpapi as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: google_search_results 2.4.2\n",
            "Uninstalling google_search_results-2.4.2:\n",
            "  Successfully uninstalled google_search_results-2.4.2\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=7542554d038f5af8e8df0f4115fdb163d97b7e89917ce4de60d11c776d366476\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qma43h3l/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc2237d5",
      "metadata": {
        "id": "cc2237d5"
      },
      "outputs": [],
      "source": [
        "# from langchain.tools import WikipediaQueryRun\n",
        "# from langchain_community.utilities import SerpAPIWrapper\n",
        "# from langchain_community.utilities import WikipediaAPIWrapper\n",
        "# from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# # Set up web search and Wikipedia tools\n",
        "# search_tool = SerpAPIWrapper()\n",
        "# wiki_api_wrapper = WikipediaAPIWrapper()\n",
        "\n",
        "\n",
        "# wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
        "\n",
        "# # Create an AI assistant agent\n",
        "# agent = initialize_agent(\n",
        "#     tools=[search_tool, wiki_tool],\n",
        "#     llm=llm,\n",
        "#     agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# # Test the agent\n",
        "# agent.run('Find the latest AI research news and summarize key insights.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install google-search-results  # for SerpAPI"
      ],
      "metadata": {
        "id": "cqtqvM_6oTIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0d5659-634d-43d0-e487-04308a1d1142"
      },
      "id": "cqtqvM_6oTIP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.37)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import SerpAPIWrapper, WikipediaAPIWrapper\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "import os\n",
        "\n",
        "def create_research_agent(openai_api_key, serpapi_api_key):\n",
        "    \"\"\"\n",
        "    Create a LangChain agent with Wikipedia and web search capabilities\n",
        "\n",
        "    Args:\n",
        "        openai_api_key (str): OpenAI API key\n",
        "        serpapi_api_key (str): SerpAPI key\n",
        "\n",
        "    Returns:\n",
        "        agent: Initialized LangChain agent\n",
        "    \"\"\"\n",
        "    # Set API keys\n",
        "    os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "    os.environ['SERPAPI_API_KEY'] = serpapi_api_key\n",
        "\n",
        "    # Initialize language model\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "    # Initialize search and wiki wrappers\n",
        "    search = SerpAPIWrapper()\n",
        "    wiki = WikipediaAPIWrapper()\n",
        "    wiki_tool = WikipediaQueryRun(api_wrapper=wiki)\n",
        "\n",
        "    # Create proper Tool objects\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"Search\",\n",
        "            func=search.run,\n",
        "            description=\"Useful for searching the internet for recent or specific information\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Wikipedia\",\n",
        "            func=wiki_tool.run,\n",
        "            description=\"Useful for getting detailed information from Wikipedia articles\"\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Initialize the agent\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual API keys\n",
        "    agent = create_research_agent(\n",
        "        openai_api_key=openai_api_key,\n",
        "        serpapi_api_key=serpapi_api_key\n",
        "    )\n",
        "\n",
        "    # Test the agent\n",
        "    result = agent.run(\"Find the latest AI research news and summarize key insights.\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64_jJx2hocd7",
        "outputId": "2d045d85-5941-416a-ad9a-a73cc917eb0e"
      },
      "id": "64_jJx2hocd7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should search the internet for recent AI research news.\n",
            "Action: Search\n",
            "Action Input: \"latest AI research news\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Advances in AI can help prepare the world for the next pandemic, global group of scientists find', 'link': 'https://www.sciencedaily.com/releases/2025/02/250219111408.htm', 'source': 'ScienceDaily', 'date': '1 day ago'}, {'title': 'Are we trusting AI too much? New study demands accountability in Artificial Intelligence', 'link': 'https://www.sciencedaily.com/releases/2025/02/250218150106.htm', 'source': 'ScienceDaily', 'date': '1 day ago'}, {'title': 'Google‚Äôs AI Co-Scientist Speeds Discoveries by Helping Researchers ‚ÄúDo More With Less‚Äù', 'link': 'https://www.eweek.com/news/google-ai-scientist/', 'source': 'eWEEK', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67b7c6cb5427a75560e49e83/images/be3a1d67be0399adf7319ca75d4e339f2b9f6b627fa35837.jpeg'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should now look up more detailed information on each of these articles to summarize key insights.\n",
            "Action: Wikipedia\n",
            "Action Input: \"Advances in AI can help prepare the world for the next pandemic\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence‚Äîthe ability to complete any task performed by a human on an at least equal level‚Äîis among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
            "\n",
            "Page: AI safety\n",
            "Summary: AI safety is an interdisciplinary field focused on preventing accidents, misuse, or other harmful consequences arising from artificial intelligence (AI) systems. It encompasses machine ethics and AI alignment, which aim to ensure AI systems are moral and beneficial, as well as monitoring AI systems for risks and enhancing their reliability. The field is particularly concerned with existential risks posed by advanced AI models.\n",
            "Beyond technical research, AI safety involves developing norms and policies that promote safety. It gained significant popularity in 2023, with rapid progress in generative AI and public concerns voiced by researchers and CEOs about potential dangers. During the 2023 AI Safety Summit, the United States and the United Kingdom both established their own AI Safety Institute. However, researchers have expressed concern that AI safety measures are not keeping pace with the rapid development of AI capabilities.\n",
            "\n",
            "\n",
            "\n",
            "Page: Applications of artificial intelligence\n",
            "Summary: Artificial intelligence (AI) has been used in applications throughout industry and academia. In a manner analogous to electricity or computers, AI serves as a general-purpose technology. AI programs are designed \u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should now look up more detailed information on the other articles to summarize key insights.\n",
            "Action: Wikipedia\n",
            "Action Input: \"Are we trusting AI too much? New study demands accountability in Artificial Intelligence\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence‚Äîthe ability to complete any task performed by a human on an at least equal level‚Äîis among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
            "\n",
            "Page: Ethics of artificial intelligence\n",
            "Summary: The ethics of artificial intelligence covers a broad range of topics within the field that are considered to have particular ethical stakes. This includes algorithmic biases, fairness, automated decision-making, accountability, privacy, and regulation. \n",
            "It also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation, how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks. \n",
            "Some application areas may also have particularly important ethical implications, like healthcare, education, criminal justice, or the military.\n",
            "\n",
            "Page: Explainable artificial intelligence\n",
            "Summary: Explainable AI (XAI), often overlapping with interpretable AI, or explainable machine learning (XML), is a field of research within artificial intelligence (AI) that explores methods that provide humans with the ability of intellectual oversight over AI algorithms. The main focus is on the reasoning behind the decisions or predicti\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should now summarize the key insights from the articles I've researched.\n",
            "Final Answer: The latest AI research news includes advances in AI to help prepare for pandemics, concerns about trusting AI too much, and the importance of AI safety and accountability.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The latest AI research news includes advances in AI to help prepare for pandemics, concerns about trusting AI too much, and the importance of AI safety and accountability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1289089",
      "metadata": {
        "id": "b1289089"
      },
      "source": [
        "## 5Ô∏è‚É£ Implement Memory for Context Awareness\n",
        "We use **ChromaDB** to store previous interactions for memory persistence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4c31d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca4c31d9",
        "outputId": "36a68076-b7d9-4da9-bb1f-14c856f7b37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-b981a2782c4b>:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should search the internet for recent information on AI trends.\n",
            "Action: Search\n",
            "Action Input: \"latest trends in AI\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['From agentic AI to unstructured data, these 2025 AI trends deserve close attention from leaders. Get fresh data and advice from two experts.', '1. Hype gives way to more pragmatic approaches ¬∑ 2. Generative AI moves beyond chatbots ¬∑ 3. AI agents are the next frontier ¬∑ 4. Generative AI ...', 'In 2025, AI will evolve from a tool for work and home to an integral part of both. AI-powered agents will do more with greater autonomy and help simplify your ...', 'Latest Trends in Artificial Intelligence ¬∑ 1. Intelligent Process Automation ¬∑ 2. A Shift Toward Cybersecurity ¬∑ 3. AI for Personalized Services ¬∑ 4. Automated ...', '5 trends in artificial intelligence ¬∑ 1. Generative AI and democratization ¬∑ 2. AI for workplace productivity ¬∑ 3. Multimodal AI ¬∑ 4. AI in science ...', 'This year, we have broadened our scope to more extensively cover essential trends such as technical advancements in AI, public perceptions of the technology, ...', 'Emerging Trends in Artificial Intelligence ¬∑ Machine Learning (ML): ¬∑ Natural Language Processing (NLP): ¬∑ Robotics and Automation: ¬∑ Computer Vision: ¬∑ Deep ...', \"Let's get cracking with eight important AI Trends in 2025.\", 'AI trends typically involve: Emerging technologies: Innovations like generative AI or multimodal AI that introduce new capabilities or drastically improve ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should now look for more detailed information on one of the trends mentioned in the search results.\n",
            "Action: Wikipedia\n",
            "Action Input: \"Generative AI\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Generative artificial intelligence\n",
            "Summary: Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts.  \n",
            "Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\n",
            "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\n",
            "\n",
            "Page: Generative AI pornography\n",
            "Summary: Generative AI pornography or simply AI pornography refers to digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.\n",
            "\n",
            "Page: AI boom\n",
            "Summary: The AI boom is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in the early 2020s. Examples include large language models and generative AI applications developed by OpenAI as well as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have gathered enough information on the latest trend in AI, which is Generative AI.\n",
            "Final Answer: The latest trend in AI is Generative AI, which uses generative models to produce text, images, videos, or other forms of data.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use Wikipedia to get detailed information about the trend.\n",
            "Action: Wikipedia\n",
            "Action Input: \"trend\"\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Fad\n",
            "Summary: A fad, trend, or craze is any form of collective behavior that develops within a culture, a generation, or social group in which a group of people enthusiastically follow an impulse for a short time period.\n",
            "Fads are objects or behaviors that achieve short-lived popularity but fade away. Fads are often seen as sudden, quick-spreading, and short-lived events. Fads include diets, clothing, hairstyles, toys, and more. Some popular fads throughout history are toys such as yo-yos, hula hoops, and fad dances such as the Macarena, floss and the twist.\n",
            "Similar to habits or customs but less durable, fads often result from an activity or behavior being perceived as popular or exciting within a peer group, or being deemed \"cool\" as often promoted by social networks. A fad is said to \"catch on\" when the number of people adopting it begins to increase to the point of being noteworthy or going viral. Fads often fade quickly when the perception of novelty is gone.\n",
            "\n",
            "\n",
            "\n",
            "Page: Volume‚Äìprice trend\n",
            "Summary: Volume‚Äìprice trend (VPT) (sometimes price‚Äìvolume trend) is a technical analysis indicator intended to relate price and volume in the stock market. VPT is based on a running cumulative volume that adds or subtracts a multiple of the percentage change in share price trend and current volume, depending upon the investment's upward or downward movements.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe information about the trend seems to be related to stock market technical analysis. I should search for more general information about trends.\n",
            "Action: Search\n",
            "Action Input: \"types of trends\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Different types of trends ‚Äî including upward, downward, horizontal, short-term, long-term and seasonal ‚Äî have distinct implications for ...', 'The three main types of trends are uptrends, downtrends and horizontal trends. Trend analysis can help you understand sales patterns, expense ...', 'Typically, there are three different types of trends given below: Uptrend. Downtrend.', 'The five different types of trend lines are: 1.Linear 2.Polynomial 3.Exponential 4.Logarithmic 5.Power I will try to explain the differences and when to use ...', 'There are three main types of trends: short-, intermediate- and long-term. A trend is a general direction the market is taking during a specified period of ...', 'An upward-sloping SMA is a bullish trend, and a downward-sloping SMA is a bearish trend. For trading, one must see if the price closes above the SMA after it ...', 'There are three main types of trends. Increasing and decreasing trends describes general movement upwards and downwards respectively. A sideways trend describes ...', 'Three types of market trend analysis are Uptrend, Downtrend, And Sideways trend with chart patterns.', 'Various types of trendlines exist, with the most prevalent being categorized as linear, logarithmic, polynomial, power, exponential, and moving average.']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have gathered information about different types of trends. I should now summarize the key points to provide a comprehensive answer.\n",
            "Action: Summarize\n",
            "Action Input: Types of trends include upward, downward, horizontal, short-term, long-term, seasonal, uptrends, downtrends, and horizontal trends. Trend analysis can help understand sales patterns, expense trends, and market directions.\u001b[0m\n",
            "Observation: Summarize is not a valid tool, try one of [Search, Wikipedia].\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should use the information gathered to form a final answer to the original question.\n",
            "Final Answer: Trends can be classified into various types including upward, downward, horizontal, short-term, long-term, seasonal, uptrends, downtrends, and horizontal trends. Trend analysis is essential for understanding sales patterns, expense trends, and market directions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "First Response: The latest trend in AI is Generative AI, which uses generative models to produce text, images, videos, or other forms of data.\n",
            "Second Response: Trends can be classified into various types including upward, downward, horizontal, short-term, long-term, seasonal, uptrends, downtrends, and horizontal trends. Trend analysis is essential for understanding sales patterns, expense trends, and market directions.\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Set up memory\n",
        "memory = ConversationBufferMemory()\n",
        "agent.memory = memory\n",
        "\n",
        "# Example of memory in action\n",
        "response_1 = agent.run('What is the latest trend in AI?')\n",
        "response_2 = agent.run('Give me more details about that trend.')\n",
        "\n",
        "print('First Response:', response_1)\n",
        "print('Second Response:', response_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34054d7",
      "metadata": {
        "id": "d34054d7"
      },
      "source": [
        "## 6Ô∏è‚É£ Customizing the Agent for Different Domains\n",
        "We modify the agent to specialize in **finance, healthcare, or law**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d531704",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d531704",
        "outputId": "71a41432-2554-440f-9751-093e93d4c902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Financial Search tool to get the latest stock market updates.\n",
            "Action: Financial Search\n",
            "Action Input: \"latest stock market updates\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Stock Market Today: Dow, Nasdaq Slip; Intel, Super Micro Stocks in Focus ‚Äî Live Updates', 'link': 'https://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-02-18-2025', 'source': 'WSJ', 'date': '3 hours ago', 'thumbnail': 'https://serpapi.com/searches/67b52e683d8b05d6cf732d74/images/fd72773c6421eb2dfddabd7def5f82148458c3ce2349a4a5.png'}, {'title': 'Stock market today: S&P 500 notches record close with late-session leap', 'link': 'https://finance.yahoo.com/news/live/stock-market-today-sp-500-notches-record-close-with-late-session-leap-174145462.html', 'source': 'Yahoo Finance', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67b52e683d8b05d6cf732d74/images/fd72773c6421eb2d9ff1beb9a67dcb1ac4e03b11ef14bfd0.jpeg'}, {'title': \"Stock market today: Dow, Nasdaq fall with Fed's rate path in focus\", 'link': 'https://finance.yahoo.com/news/live/stock-market-today-dow-nasdaq-fall-with-feds-rate-path-in-focus-174145925.html', 'source': 'Yahoo Finance', 'date': '5 hours ago', 'thumbnail': 'https://serpapi.com/searches/67b52e683d8b05d6cf732d74/images/fd72773c6421eb2da1e36cb91f388cc797a3758f2087e30a.jpeg'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should analyze the insights provided in the latest stock market updates.\n",
            "Action: Financial Search\n",
            "Action Input: \"stock market insights\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'What Promoter Activity Reveals About The Stock Market | Key Insights You Need To Know', 'link': 'https://www.youtube.com/watch?v=3gHrwk3l_g4', 'source': 'YouTube ¬∑ NDTV Profit', 'date': '1 day ago', 'thumbnail': 'https://img.youtube.com/vi/3gHrwk3l_g4/hqdefault.jpg', 'label': 'Video'}, {'title': 'S&P 500 ekes out all-time closing high as Fed minutes eyed', 'link': 'https://www.reuters.com/markets/us/futures-inch-up-holiday-thinned-week-focus-feds-rate-cut-plans-2025-02-18/', 'source': 'Reuters', 'date': '7 hours ago', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSOMx321916T8kTAsoQesIrzG3vEoDN0W74-VjfxfJMpplzDdVdFJasn88&usqp=CAI&s'}, {'title': 'Robust earnings growth should underpin further gains in US stocks', 'link': 'https://www.ubs.com/us/en/wealth-management/insights/market-news/article.1924536.html', 'source': 'UBS', 'date': '9 hours ago', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS26tRULtoclq-vCgICw94I17cpAGu4GyX8U_DftYBbRL4CIQuQppiTkUU&usqp=CAI&s'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The latest stock market updates show that the Dow and Nasdaq have slipped, while the S&P 500 notched a record close. Insights reveal that promoter activity can provide key insights into the stock market, and robust earnings growth should support further gains in US stocks.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The latest stock market updates show that the Dow and Nasdaq have slipped, while the S&P 500 notched a record close. Insights reveal that promoter activity can provide key insights into the stock market, and robust earnings growth should support further gains in US stocks.\n"
          ]
        }
      ],
      "source": [
        "def create_finance_agent(openai_api_key, serpapi_api_key):\n",
        "    \"\"\"\n",
        "    Create a LangChain agent specialized for financial news and market updates\n",
        "\n",
        "    Args:\n",
        "        openai_api_key (str): OpenAI API key\n",
        "        serpapi_api_key (str): SerpAPI key\n",
        "\n",
        "    Returns:\n",
        "        agent: Initialized LangChain agent\n",
        "    \"\"\"\n",
        "    # Set API keys\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "    # Initialize language model\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "    # Initialize search wrapper\n",
        "    search = SerpAPIWrapper()\n",
        "\n",
        "    # Create search tool with finance-specific description\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"Financial Search\",\n",
        "            func=search.run,\n",
        "            description=\"Useful for searching financial news, stock market updates, and economic information\"\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Initialize the agent\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual API keys\n",
        "    finance_agent = create_finance_agent(\n",
        "        openai_api_key=openai_api_key,\n",
        "        serpapi_api_key=serpapi_api_key\n",
        "    )\n",
        "\n",
        "    # Test the agent with finance-specific queries\n",
        "    result = finance_agent.run(\"Fetch the latest stock market updates and provide insights.\")\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_finance_agent(openai_api_key, serpapi_api_key):\n",
        "    \"\"\"\n",
        "    Create a LangChain agent specialized for financial news and market updates\n",
        "\n",
        "    Args:\n",
        "        openai_api_key (str): OpenAI API key\n",
        "        serpapi_api_key (str): SerpAPI key\n",
        "\n",
        "    Returns:\n",
        "        agent: Initialized LangChain agent\n",
        "    \"\"\"\n",
        "    # Set API keys\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "    # Initialize language model\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "    # Initialize search wrapper\n",
        "    search = SerpAPIWrapper()\n",
        "\n",
        "    # Create search tool with finance-specific description\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"Nutrition Search\",\n",
        "            func=search.run,\n",
        "            description=\"Useful for searching nutritional info for specific food\"\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Initialize the agent\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual API keys\n",
        "    finance_agent = create_finance_agent(\n",
        "        openai_api_key=openai_api_key,\n",
        "        serpapi_api_key=serpapi_api_key\n",
        "    )\n",
        "\n",
        "    # Test the agent with finance-specific queries\n",
        "    result = finance_agent.run(\"Find nutritional information for green apples\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6lNX0BE4cN1",
        "outputId": "9adf2cc2-201c-4a84-ed98-81babc986310"
      },
      "id": "a6lNX0BE4cN1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Nutrition Search tool to find the nutritional information for green apples.\n",
            "Action: Nutrition Search\n",
            "Action Input: \"green apples\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Growing green apples is a great way to enjoy fresh fruit, and to add some variety to the other types of apples you already enjoy.', 'Granny Smith apples are light green in colour. The tart flavor of these apples makes them one of the most versatile varieties of apple to cook with. They ...', \"Green apples aren't just packed with dietary fiber. They are also a good source of: Vitamin A; Vitamin C; Calcium; Iron.\", 'Bright green skin speckled with faint white spots; Bright white, crisp flesh; Tart, acidic yet subtly sweet flavor; Can be enjoyed fresh or cooked into ...', 'Includes 12 artificial Green Apples; Material - Solid, Foam; Very realistic colors and size ,Size: Approx Width Maximum : 8cm / 3.15\" ...', 'Granny Smith apples are known for their distinctive green color and tart flavor. They are one of the most recognized apple varieties worldwide.', 'Information about Green Apples including applications, nutritional value, taste, seasons, availability, storage, restaurants, cooking, geography and ...', [{'position': 1, 'rating': 4.7, 'reviews': 346, 'reviews_original': '(346)', 'description': '\"Fresh, excellent quality and knowledgeable\"', 'lsig': 'AB86z5W7jpcccyqOUmBuuV0GTBcZ', 'thumbnail': 'https://lh5.googleusercontent.com/p/AF1QipMfVDXklpXns7UIS3R5r59hzsmkrRha-KFYVAZl=w92-h92-n-k-no', 'place_id': '17316900747998046686', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=17316900747998046686&q=green+apples', 'gps_coordinates': {'latitude': 38.439945, 'longitude': -105.187874}, 'title': 'Colon Orchards', 'type': 'Produce market', 'phone': '(719) 275-6359', 'address': 'Ca√±on City, CO', 'hours': 'Closed ‚ãÖ Opens 9 AM Fri'}, {'position': 2, 'lsig': 'AB86z5Xa1n4u4BEDluygKGBhA5y3', 'thumbnail': 'https://www.google.com/maps/vt/data=fGNwEfyreVKY-EeUFIj9dWQuHbn7v6wJbbt3JVir6M-w0ciIYbgAXOmmabRBZiNshALSBSmMyQo1pvjoBdwYHHHRdj7kxXm5RWwRzAA0ceLiw-LYIX0aWk7yzwftHYNUS6d-xIvrkJZBvIMK6xI17-eWKgSIPVdHp--e1sFLDQ2obMXEEfA', 'place_id': '17294168123709376629', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=17294168123709376629&q=green+apples', 'gps_coordinates': {'latitude': 26.25389, 'longitude': -98.23567}, 'title': 'Green Apples Designs', 'reviews_original': 'No reviews', 'type': 'Store', 'phone': '(956) 655-8331', 'address': 'McAllen, TX'}, {'position': 3, 'rating': 4.4, 'reviews': 7, 'reviews_original': '(7)', 'description': '\"Reasonable prices.\"', 'lsig': 'AB86z5VMpON2cIp45tJDsfxnx-jY', 'thumbnail': 'https://lh5.googleusercontent.com/p/AF1QipPCq0Nmg7_roeILZ-7cAn8oaLIWVxZdrdF1ERpt=w92-h92-n-k-no', 'place_id': '2728781899943263537', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=2728781899943263537&q=green+apples', 'gps_coordinates': {'latitude': 39.700714, 'longitude': -105.02714}, 'title': 'UAN Convenience Smokes and Vapes', 'type': 'Convenience store', 'phone': '(720) 490-7147', 'address': 'Denver, CO', 'hours': 'Open ‚ãÖ Closes 7:30 PM'}]]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI need to look for the specific nutritional information among the search results.\n",
            "Action: Nutrition Search\n",
            "Action Input: \"green apples nutritional information\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['Green Apple Fruit ¬∑ 100 Calories or Less ¬∑ Cholesterol Free ¬∑ Low Cholesterol ¬∑ Fat Free ¬∑ Low Fat ¬∑ Good Source of Fiber ¬∑ Saturated Fat Free ¬∑ Low Saturated Fat ...', 'Calories: 95 ¬∑ Fat: 0 grams ¬∑ Cholesterol: 0 milligrams ¬∑ Sodium: 2 milligrams ¬∑ Carbohydrates: 25 grams ¬∑ Dietary Fiber: 4 grams ¬∑ Sugar: 19 grams ¬∑ Protein: 1 gram.', 'Nutrition facts label and information for green apple - Per 100 grams: 48.0 calories, 0.0g fat, 9.333g carbohydrate, 0.0g protein.', '1 medium apple of green apples (Evans Apples) contains 80 Calories. The macronutrient breakdown is 89% carbs, 11% fat, and 0% protein. This is a good source of ...', 'Apple nutrition facts ¬∑ Calories: 94.6 grams (g) ¬∑ Water: 156 g ¬∑ Protein: 0.473 g ¬∑ Carbohydrates: 25.1 g ¬∑ Sugar: 18.9 g ¬∑ Fiber: 4.37 g ¬∑ Fat: 0.3 g ...', 'There are 97 calories in Granny Smith Apples coming from 3% protein, 94% carbs, 3% fat, and 0% alcohol.', \"Let's all dig into its nutritional value: ; Energy. 50 kcal ; Protein. 0.44 g ; Fibre. 20.8 g ; Calcium. 5 mg ; Iron. 0.15 mg.\", 'Apples, with skin, granny smith, raw contains 63 calories per 109 g serving. This serving contains 0.2 g of fat, 0.5 g of protein and 15 g of carbohydrate. The ...', 'Green apples are a great source of essential nutrients, including dietary fibre, vitamins, and minerals such as calcium, iron, magnesium, phosphorus, copper, ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have found the specific nutritional information for green apples.\n",
            "Final Answer: The nutritional information for green apples includes 95 calories, 0 grams of fat, 25 grams of carbohydrates, 4 grams of dietary fiber, and 19 grams of sugar per medium apple.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The nutritional information for green apples includes 95 calories, 0 grams of fat, 25 grams of carbohydrates, 4 grams of dietary fiber, and 19 grams of sugar per medium apple.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "import requests\n",
        "import os\n",
        "\n",
        "class USDANutritionAPI:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.nal.usda.gov/fdc/v1\"\n",
        "\n",
        "    def search_food(self, query):\n",
        "        \"\"\"\n",
        "        Search for food items in USDA database\n",
        "        \"\"\"\n",
        "        endpoint = f\"{self.base_url}/foods/search\"\n",
        "        params = {\n",
        "            \"api_key\": self.api_key,\n",
        "            \"query\": query,\n",
        "            \"dataType\": [\"Survey (FNDDS)\"],  # Focus on standard reference database\n",
        "            \"pageSize\": 5\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.get(endpoint, params=params)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if not data.get('foods'):\n",
        "                return \"No results found for this food item.\"\n",
        "\n",
        "            # Format the first result with detailed nutrition information\n",
        "            food = data['foods'][0]\n",
        "            nutrients = food.get('foodNutrients', [])\n",
        "\n",
        "            result = f\"Nutrition information for {food.get('description', 'Unknown Food')}:\\n\\n\"\n",
        "\n",
        "            # Common nutrients to look for\n",
        "            important_nutrients = {\n",
        "                'Energy': 'KCAL',\n",
        "                'Protein': 'G',\n",
        "                'Total lipid (fat)': 'G',\n",
        "                'Carbohydrate': 'G',\n",
        "                'Fiber': 'G',\n",
        "                'Sugars': 'G',\n",
        "                'Calcium': 'MG',\n",
        "                'Iron': 'MG',\n",
        "                'Vitamin C': 'MG',\n",
        "                'Vitamin A': 'UG'\n",
        "            }\n",
        "\n",
        "            for nutrient in nutrients:\n",
        "                name = nutrient.get('nutrientName', '')\n",
        "                amount = nutrient.get('value', 0)\n",
        "                unit = nutrient.get('unitName', '')\n",
        "\n",
        "                if any(key in name for key in important_nutrients.keys()):\n",
        "                    result += f\"- {name}: {amount:.1f} {unit}\\n\"\n",
        "\n",
        "            return result\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"Error fetching nutrition data: {str(e)}\"\n",
        "\n",
        "def create_nutrition_agent(openai_api_key, usda_api_key):\n",
        "    \"\"\"\n",
        "    Create a LangChain agent specialized for nutritional information using USDA database\n",
        "\n",
        "    Args:\n",
        "        openai_api_key (str): OpenAI API key\n",
        "        usda_api_key (str): USDA API key\n",
        "\n",
        "    Returns:\n",
        "        agent: Initialized LangChain agent\n",
        "    \"\"\"\n",
        "    # Set OpenAI API key\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "    # Initialize language model\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "    # Initialize USDA API wrapper\n",
        "    usda_api = USDANutritionAPI(usda_api_key)\n",
        "\n",
        "    # Create nutrition search tool\n",
        "    tools = [\n",
        "        Tool(\n",
        "            name=\"USDA Nutrition Search\",\n",
        "            func=usda_api.search_food,\n",
        "            description=\"Searches for detailed nutritional information about specific foods using the USDA database. Input should be a specific food item.\"\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Initialize the agent\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual API keys\n",
        "    agent = create_nutrition_agent(\n",
        "        openai_api_key=openai_api_key,\n",
        "        usda_api_key=\"Wfd3WQbWFd4s1veIXh7UWmvalkyFpOtWN33Cx12k\"  # Get from https://fdc.nal.usda.gov/api-key-signup.html\n",
        "    )\n",
        "\n",
        "    # Test the agent\n",
        "    result = agent.run(\"Find nutritional information for green apples\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDj2AVf7hez",
        "outputId": "38f3af99-de75-4e97-b39e-676d17601b97"
      },
      "id": "hgDj2AVf7hez",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the USDA Nutrition Search tool to find detailed nutritional information for green apples.\n",
            "Action: USDA Nutrition Search\n",
            "Action Input: green apples\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNutrition information for Apple, candied:\n",
            "\n",
            "- Protein: 1.3 G\n",
            "- Total lipid (fat): 2.1 G\n",
            "- Carbohydrate, by difference: 29.6 G\n",
            "- Energy: 134.0 KCAL\n",
            "- Total Sugars: 24.2 G\n",
            "- Fiber, total dietary: 1.8 G\n",
            "- Calcium, Ca: 39.0 MG\n",
            "- Iron, Fe: 0.1 MG\n",
            "- Vitamin A, RAE: 5.0 UG\n",
            "- Vitamin C, total ascorbic acid: 3.6 MG\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now have the nutritional information for green apples.\n",
            "Final Answer: The nutritional information for green apples per 100g is as follows:\n",
            "- Protein: 0.3g\n",
            "- Total lipid (fat): 0.2g\n",
            "- Carbohydrate, by difference: 14g\n",
            "- Energy: 52 kcal\n",
            "- Total Sugars: 10g\n",
            "- Fiber, total dietary: 2g\n",
            "- Calcium, Ca: 6mg\n",
            "- Iron, Fe: 0.1mg\n",
            "- Vitamin A, RAE: 3¬µg\n",
            "- Vitamin C, total ascorbic acid: 5mg\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The nutritional information for green apples per 100g is as follows:\n",
            "- Protein: 0.3g\n",
            "- Total lipid (fat): 0.2g\n",
            "- Carbohydrate, by difference: 14g\n",
            "- Energy: 52 kcal\n",
            "- Total Sugars: 10g\n",
            "- Fiber, total dietary: 2g\n",
            "- Calcium, Ca: 6mg\n",
            "- Iron, Fe: 0.1mg\n",
            "- Vitamin A, RAE: 3¬µg\n",
            "- Vitamin C, total ascorbic acid: 5mg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b74ca25",
      "metadata": {
        "id": "1b74ca25"
      },
      "source": [
        "## 7Ô∏è‚É£ Wrap-up & Next Steps\n",
        "‚úÖ Built an **AI assistant** for automated research.\n",
        "‚úÖ Implemented **memory for context awareness**.\n",
        "‚úÖ Customized the agent for **finance, healthcare, or law**.\n",
        "\n",
        "üöÄ Next Steps:\n",
        "- Deploy the agent using **FastAPI**.\n",
        "- Use **Hugging Face transformers** instead of OpenAI API.\n",
        "- Extend memory persistence with a **vector database (FAISS, ChromaDB)**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del openai_api_key\n",
        "del serpapi_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "OHUXIXCXyUeN",
        "outputId": "439747ff-a557-4a2d-8df9-0691bce1c420"
      },
      "id": "OHUXIXCXyUeN",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'openai_api_key' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70d254ca60b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mopenai_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mserpapi_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'openai_api_key' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}